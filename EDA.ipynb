{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json as js\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "import re\n",
    "import os\n",
    "import itertools\n",
    "import jieba\n",
    "import jieba.posseg as posseg\n",
    "from jieba.analyse import extract_tags\n",
    "from jieba.analyse import textrank\n",
    "from collections import defaultdict\n",
    "from zhon.hanzi import punctuation as chinese_punc\n",
    "from string import punctuation as english_punc\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "# this might be a bad habbit ..-\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './data/doc_quality_data_train.json'\n",
    "test_data_path = './data/doc_quality_data_test.json'\n",
    "train_sample_path = './data/doc_sample_data_train.json'\n",
    "test_size = 45286\n",
    "train_size = 576454"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "different types of articles seems to be in quite different writing style, such as sentence length and number of paragraph (some writers like to write paragraph with only one sentence). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract writing charateristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(train_sample_path):\n",
    "    with open(train_data_path, 'r') as f:\n",
    "        s = []\n",
    "        for i in range(100):\n",
    "            s.append(f.readline())\n",
    "    with open(train_sample_path, 'w') as f:\n",
    "        f.writelines(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what we need\n",
    "\n",
    "# 标题\n",
    "title_num_char = [] # 标题长度\n",
    "title_num_word = [] # 标题词总数\n",
    "title_num_keyword = [] # 标题关键词总数\n",
    "title_ratio_keyword = [] # 标题关键词总数/标题词总数\n",
    "\n",
    "# 字符层级\n",
    "num_char = [] # 字符总数\n",
    "num_char_del_stop = [] # 删除停词后的字符总数\n",
    "num_uni_char = [] # 不同字符总数\n",
    "ratio_uni_char = [] # 不同字符总数/字符总数\n",
    "num_punc = [] # 标点符号总数\n",
    "ratio_punc = [] # 标点符号总数/字符总数\n",
    "\n",
    "# 词层级, 分词后\n",
    "num_word = [] # 词总数\n",
    "num_uni_word = [] # 不同词总数\n",
    "ratio_uni_word = [] # 不同词总数/词总数\n",
    "\n",
    "# 词性\n",
    "num_noun = [] # 名词总数\n",
    "num_adj = [] # 形容词总数\n",
    "num_verb = [] # 动词总数\n",
    "num_adv = [] # 副词总数\n",
    "num_conj = [] # 连词总数\n",
    "num_numeral = [] # 数词总数\n",
    "\n",
    "ratio_noun = [] # 名词/词总数\n",
    "ratio_adj = [] # 形容词/词总数\n",
    "ratio_verb = [] # 动词/词总数\n",
    "ratio_adv = [] # 副词/词总数\n",
    "ratio_conj = [] # 连词/词总数\n",
    "ratio_numeral = [] # 数词总数\n",
    "\n",
    "# 段落\n",
    "num_para = [] # 段落数\n",
    "ratio_char_para = [] # 字符总数/段落数\n",
    "ratio_word_para = [] # 词总数/段落数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､　、〃〈〉《》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏﹑﹔·！？｡。!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*']\n"
     ]
    }
   ],
   "source": [
    "punc = chinese_punc + english_punc\n",
    "with open('./stopwords.txt', 'r') as f:\n",
    "    stop_words = f.readlines()\n",
    "stop_words = [ c[:-1] for c in stop_words ] + list(punc)\n",
    "print(\n",
    "    punc,\n",
    "    stop_words[0:10],\n",
    "    sep = '\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn* : noun,\\nv* : verb,\\na* : adj,\\nd* : adv,\\nm* : numeral,\\nc* : conjucture\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topK = 10\n",
    "allowPOS = ['ns', 'n', 'vn', 'v','nr']\n",
    "baseNum = 10000\n",
    "'''\n",
    "n* : noun,\n",
    "v* : verb,\n",
    "a* : adj,\n",
    "d* : adv,\n",
    "m* : numeral,\n",
    "c* : conjucture\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'title', 'category', 'title_num_char', 'title_num_word',\n",
    "       'title_num_keyword', 'num_char', 'num_char_del_stop', 'num_uni_char',\n",
    "       'num_punc', 'num_word', 'num_uni_word', 'num_noun', 'num_adj',\n",
    "       'num_verb', 'num_adv', 'num_conj', 'num_numeral', 'num_para'] # + ['doctype']\n",
    "\n",
    "def extract_WC(cnt:int, l:str, template:str):\n",
    "    if os.path.exists(template.format(cnt)):\n",
    "        return\n",
    "    \n",
    "    line = js.loads(l)\n",
    "    title_num_char = len(line['title'])\n",
    "    num_char = len(line['body'])\n",
    "    num_uni_char = len(set(line['body']))\n",
    "\n",
    "    pos_body = list(posseg.cut(line['body']))\n",
    "    num_uni_word = len(set(pos_body))\n",
    "    num_word = len(pos_body)\n",
    "\n",
    "    temp = defaultdict(int)\n",
    "    for (w, p) in pos_body:\n",
    "        #print(p[0], end = '')\n",
    "        temp[p[0]] += 1\n",
    "        if not w in stop_words:\n",
    "            temp['nw'] += 1\n",
    "    #print(temp)\n",
    "\n",
    "    num_noun = temp['n']\n",
    "    num_adj = temp['a']\n",
    "    num_adv = temp['d']\n",
    "    num_verb = temp['v']\n",
    "    num_conj = temp['c']\n",
    "    num_numeral = temp['m']\n",
    "    num_punc = temp['x']\n",
    "    num_char_del_stop = temp['nw']\n",
    "    kws = extract_tags(\n",
    "        line['body'],\n",
    "        topK=topK,\n",
    "        allowPOS=allowPOS\n",
    "    )\n",
    "    title_num_word = len(list(jieba.cut(line['title'])))\n",
    "    for kw in kws:\n",
    "        temp['kw'] += line['title'].count(kw)\n",
    "    title_num_keyword = temp['kw']\n",
    "\n",
    "    num_para = len(re.findall('\\s*\\n\\s*', line['body'].strip())) + 1\n",
    "    s = [\n",
    "        line['id'],\n",
    "        line['title'],\n",
    "        line['category'],\n",
    "        title_num_char,\n",
    "        title_num_word,\n",
    "        title_num_keyword,\n",
    "        num_char,\n",
    "        num_char_del_stop,\n",
    "        num_uni_char,\n",
    "        num_punc,\n",
    "        num_word,\n",
    "        num_uni_word,\n",
    "        num_noun,\n",
    "        num_adj,\n",
    "        num_verb,\n",
    "        num_adv,\n",
    "        num_conj,\n",
    "        num_numeral,\n",
    "        num_para\n",
    "    ]\n",
    "    if 'doctype' in line:\n",
    "        s.append(line['doctype'])\n",
    "    with open(template.format(cnt), 'w') as f:\n",
    "        f.write(','.join([str(i) for i in s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with 10000 samples\n",
      "done with 20000 samples\n",
      "done with 30000 samples\n",
      "done with 40000 samples\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "path = './data/raw_test_wc.csv'\n",
    "if not os.path.exists(path):\n",
    "    pool = mp.Pool(3)\n",
    "    num = 0\n",
    "    template = './data/test/test_{}.csv'\n",
    "    with open(test_data_path, 'r') as f:\n",
    "        for (cnt, l) in enumerate(f):\n",
    "            pool.apply_async(func = extract_WC, args = (cnt, l, template))\n",
    "            num += 1\n",
    "            if num % 10000 == 0:\n",
    "                print(f'done with {num} samples')\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    }
   ],
   "source": [
    "path = './data/raw_train_wc.csv'\n",
    "if not os.path.exists(path):\n",
    "    pool = mp.Pool(3)\n",
    "    num = mp.Value('i', 0)\n",
    "    template = './data/train/train_{}.csv'\n",
    "    with open(train_data_path, 'r') as f:\n",
    "        for (cnt, l) in enumerate(f):\n",
    "            pool.apply_async(func = extract_WC, args = (cnt, l, template))\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with 0/45286\n",
      "done with 10000/45286\n",
      "done with 20000/45286\n",
      "done with 30000/45286\n",
      "done with 40000/45286\n",
      "test_45285 not found\n",
      "4638 40647\n",
      "45285\n"
     ]
    }
   ],
   "source": [
    "# test files\n",
    "path = './data/raw_test_wc.csv'\n",
    "cols = ['id', 'title', 'category', 'title_num_char', 'title_num_word',\n",
    "       'title_num_keyword', 'num_char', 'num_char_del_stop', 'num_uni_char',\n",
    "       'num_punc', 'num_word', 'num_uni_word', 'num_noun', 'num_adj',\n",
    "       'num_verb', 'num_adv', 'num_conj', 'num_numeral', 'num_para'] # + ['doctype']\n",
    "ncols = len(cols)\n",
    "df_list = []\n",
    "ab_list = []\n",
    "if not os.path.exists(path):\n",
    "    for i in range(0, test_size):\n",
    "        if not os.path.exists(f'./data/test/test_{i}.csv'):\n",
    "            print(f'test_{i} not found')\n",
    "            continue\n",
    "        with open(f'./data/test/test_{i}.csv', 'r') as t:\n",
    "            l = t.read().split(',')\n",
    "            if len(l) == ncols:\n",
    "                df_list.append(l)\n",
    "            else:\n",
    "                ab_list.append(l)\n",
    "        if i % 10000 == 0:\n",
    "            print(f'done with {i}/{test_size}')\n",
    "\n",
    "print(len(ab_list), len(df_list))\n",
    "\n",
    "#deal with abnormal samples\n",
    "for l in ab_list:\n",
    "    p = [l[0]] + [','.join(l[1 : len(l)-17])] + l[len(l)-17:]\n",
    "    df_list.append(p)\n",
    "print(len(df_list))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    df_list,\n",
    "    columns = cols\n",
    ")\n",
    "\n",
    "df.to_csv(path, index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/raw_train_wc.csv'\n",
    "if not os.path.exists(path):\n",
    "    f = open(path, 'w')\n",
    "    f.write(','.join(cols + ['doctype']) + '\\n')\n",
    "    for i in range(0, 576453):\n",
    "        with open(f'./data/train/train_{i}.csv', 'r') as t:\n",
    "            f.writelines(t.readlines())\n",
    "        if i % 10000 == 0:\n",
    "            print(f'done with {i}/576453')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with 0/576454\n",
      "done with 100000/576454\n",
      "done with 200000/576454\n",
      "done with 300000/576454\n",
      "done with 400000/576454\n",
      "done with 500000/576454\n",
      "26651 549803\n"
     ]
    }
   ],
   "source": [
    "path = './data/raw_train_wc.csv'\n",
    "cols = ['id', 'title', 'category', 'title_num_char', 'title_num_word',\n",
    "       'title_num_keyword', 'num_char', 'num_char_del_stop', 'num_uni_char',\n",
    "       'num_punc', 'num_word', 'num_uni_word', 'num_noun', 'num_adj',\n",
    "       'num_verb', 'num_adv', 'num_conj', 'num_numeral', 'num_para', 'doctype']\n",
    "ncols = len(cols)\n",
    "df_list = []\n",
    "ab_list = []\n",
    "if not os.path.exists(path):\n",
    "    for i in range(0, train_size):\n",
    "        if not os.path.exists(f'./data/train/train_{i}.csv'):\n",
    "            print(f'train_{i} not found')\n",
    "            continue\n",
    "        with open(f'./data/train/train_{i}.csv', 'r') as t:\n",
    "            l = t.read().split(',')\n",
    "            if len(l) == ncols:\n",
    "                df_list.append(l)\n",
    "            else:\n",
    "                ab_list.append(l)\n",
    "        if i % 100000 == 0:\n",
    "            print(f'done with {i}/{train_size}')\n",
    "\n",
    "print(len(ab_list), len(df_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576454\n"
     ]
    }
   ],
   "source": [
    "#deal with abnormal samples\n",
    "for l in ab_list:\n",
    "    p = [l[0]] + [','.join(l[1 : len(l)-18])] + l[len(l)-18:]\n",
    "    #print(l,p,sep = '\\n',end = '\\n\\n')\n",
    "    df_list.append(p)\n",
    "print(len(df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    df_list,\n",
    "    columns = cols\n",
    ")\n",
    "\n",
    "df.to_csv(path, index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decide doc length and sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_version = 'bert-base-chinese'\n",
    "prep = Preprocessor(bert_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = './data/training_set.csv'\n",
    "ds = pd.read_csv(p)\n",
    "ds = ds[ds.body.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 576466 entries, 0 to 576508\n",
      "Data columns (total 33 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   576456 non-null  object \n",
      " 1   title                576466 non-null  object \n",
      " 2   body                 576466 non-null  object \n",
      " 3   category             576454 non-null  float64\n",
      " 4   title_num_char       576454 non-null  float64\n",
      " 5   title_num_word       576454 non-null  float64\n",
      " 6   title_num_keyword    576454 non-null  float64\n",
      " 7   num_char             576454 non-null  float64\n",
      " 8   num_char_del_stop    576454 non-null  float64\n",
      " 9   num_uni_char         576454 non-null  float64\n",
      " 10  num_punc             576454 non-null  float64\n",
      " 11  num_word             576454 non-null  float64\n",
      " 12  num_uni_word         576454 non-null  float64\n",
      " 13  num_noun             576454 non-null  float64\n",
      " 14  num_adj              576454 non-null  float64\n",
      " 15  num_verb             576454 non-null  float64\n",
      " 16  num_adv              576454 non-null  float64\n",
      " 17  num_conj             576454 non-null  float64\n",
      " 18  num_numeral          576454 non-null  float64\n",
      " 19  num_para             576454 non-null  float64\n",
      " 20  title_ratio_keyword  576454 non-null  float64\n",
      " 21  ratio_uni_char       576454 non-null  float64\n",
      " 22  ratio_uni_word       576454 non-null  float64\n",
      " 23  ratio_punc           576454 non-null  float64\n",
      " 24  ratio_noun           576454 non-null  float64\n",
      " 25  ratio_verb           576454 non-null  float64\n",
      " 26  ratio_adj            576454 non-null  float64\n",
      " 27  ratio_adv            576454 non-null  float64\n",
      " 28  ratio_conj           576454 non-null  float64\n",
      " 29  ratio_numeral        576454 non-null  float64\n",
      " 30  ratio_char_para      576442 non-null  float64\n",
      " 31  ratio_word_para      576442 non-null  float64\n",
      " 32  doctype              76454 non-null   object \n",
      "dtypes: float64(29), object(4)\n",
      "memory usage: 149.5+ MB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.body = ds.title + '。' + ds.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_sent_char(d):\n",
    "    s = prep.cut_doc(d)\n",
    "    print(i)\n",
    "    return [len(i) for i in s]\n",
    "\n",
    "def count_doc_sent(d):\n",
    "    return len(prep.cut_doc(d))\n",
    "\n",
    "def not_str(d):\n",
    "    return not isinstance(d,str)\n",
    "\n",
    "bad_body = ds.body[ds.body.apply(not_str)]\n",
    "bad_body.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_doc_sent = ds.body.parallel_apply(count_doc_sent)\n",
    "l = ds.body.parallel_apply(count_sent_char)\n",
    "num_sent_char = [x for y in l for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_doc_sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
